## Expectations
Before I started, my idea was to get a general idea of the different fileds of knowledge through the reproducibility of the artifacts or experiments. After all, these papers cover knowledge from different domains, such as hardware, algorithms, semantics, etc. And since, unlike academic papers from other disciplines, the SE domain is often based on some actual algorithm or software. This also makes its reproducibility much different. I hope to learn how to write a "real" SE paper based on artifacts.

## Differences across the assigned artifacts and Impact
At least in terms of the papers to which I was assigned, the artifacts in them I would broadly classify into two categories: experimental artifacts, and theoretical artifacts.
### Experimental artifacts
One very distinctive feature of these artifacts is that the entire experimental process is considered to be part of the artifact, and the paper involves, for example, an algorithm or software that serves as "tool support" for the artifact.  This type of artifact is the easiest to reproduce if accompanied by detailed guidance documentations, because it is based on a "step-by-step" process and has quantifiable or even visualized results, which makes it very easy to verify and use, and with calls to algorithms or source code integrated in some operational scripts.
### Theoretical artifacts
Theoretical artifacts are hard to reproduce the experiment. This is because most of their papers spend a lot of space on the relevant theoretical foundations. Their purpose is to illustrate the efficiency of a certain algorithm, library, or tool. However, such artifacts often do not have quantifiable metrics to illustrate their efficiency, or their efficiency needs some prior knowledge, such as semantics, to be judged. These artifacts basically do not contain data sets or input files for input. My guess is that as a "general-purpose" algorithm or tool, it would be inappropriate to use a specific input set to verify its validity. But this also makes it more difficult or impossible to perform reproducible experiments.

## Conclusions
* Even if you can successfully complete the experiment, the probability is that you will not be able to learn the relevant field of knowledge from it, because the level of these papers is not "novice tutorial level". Even for experimental artifacts, a large amount of prior knowledge is required to fully understand the knowledge and principles involved. Many papers on semantics contain much more theoretical knowledge.
* Reproducible experiments often do not require you to fully understand the content of the paper, but rather a general reading of the paper to figure out the purpose of the paper and the use of artifacts.
* Guidance documentation is extremely important for artifacts. This is because authors should not assume that the reviewer or reapplicator of the paper must have sufficient prior knowledge. From the experiments I have done, the lack of guidance documentation can lead to extremely slow progress because I cannot immediately understand the entire flow of the experiment.

## The Lessons
* Previously I thought artifact-based papers should spend a lot of time describing the details of their implementation. But this is not the case. Because this type of paper is not a "lab report", it needs more space to fill in the theoretical underpinnings and to verify success. More effort is spent on the so-called "relevant" parts.
* As I mentioned in the previous section, the importance of the guidance documentation. The guidance documentation should be seen as an interface to the artifact. And it is important to note that guidance documentations, such as README files, should have a uniform format specification. It is also important to include a directory structure and description of the artifacts in the guidance documentation, as the file structure will be useful for troubleshooting errors as they occur during the experiment.
* Sometimes artifacts fail not because of a problem with the artifact itself, but because of a significant change in the software or library on which they depend. From the point of view of verifying its reproducibility, we need to find the environment it needs to run in. But in terms of reusability, this is a great disadvantage for the artifact in a new development environment. This may require the authors to adapt the artifacts for the new development environment.
